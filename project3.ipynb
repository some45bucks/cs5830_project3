{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secret/secret.txt') as f:\n",
    "    api_key = f.readline().strip()\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_add_playlist_id_to_dataframe(dataframe, channel_ids):\n",
    "    playlist_ids = []\n",
    "    for channel_id in channel_ids:\n",
    "        request = youtube.channels().list(\n",
    "            part=\"contentDetails\",\n",
    "            id=channel_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        playlist_ids.append(response['items'][0]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "    dataframe['playlist_id'] = playlist_ids\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def get_video_data(video_data_path, channel_data):\n",
    "    if os.path.exists(video_data_path):\n",
    "        video_data = pd.read_csv(video_data_path)\n",
    "    else:\n",
    "        video_data = pd.DataFrame(columns=[\"channel_id\",\"video_id\", \"video_title\", \"publish_date\" ,\"view_count\", \"like_count\", \"dislike_count\", \"comment_count\", \"default_language\", \"duration\",\"has_paid_product_placement\"])\n",
    "\n",
    "        try:\n",
    "            for id,channel_id in zip(channel_data[\"video_id\"],channel_data[\"channel_id\"]):\n",
    "\n",
    "                video_request = youtube.videos().list(\n",
    "                    part=\"snippet,statistics,contentDetails\",\n",
    "                    id=id\n",
    "                )\n",
    "\n",
    "                video_response = video_request.execute()\n",
    "\n",
    "                for video in video_response[\"items\"]:\n",
    "\n",
    "                    try:\n",
    "                        video_id = video[\"id\"]\n",
    "                    except KeyError:\n",
    "                        video_id = float('nan')\n",
    "                    try:\n",
    "                        view_count = video[\"statistics\"][\"viewCount\"]\n",
    "                    except KeyError:\n",
    "                        view_count = float('nan')\n",
    "                    try:\n",
    "                        like_count = video[\"statistics\"][\"likeCount\"]\n",
    "                    except KeyError:\n",
    "                        like_count = float('nan')\n",
    "                    try:\n",
    "                        dislike_count = video[\"statistics\"][\"dislikeCount\"]\n",
    "                    except KeyError:\n",
    "                        dislike_count = float('nan')\n",
    "                    try:\n",
    "                        comment_count = video[\"statistics\"][\"commentCount\"]\n",
    "                    except KeyError:\n",
    "                        comment_count = float('nan')\n",
    "                    try:\n",
    "                        video_title = video[\"snippet\"][\"title\"]\n",
    "                    except KeyError:\n",
    "                        video_title = float('nan')\n",
    "                    try:\n",
    "                        publish_date = video[\"snippet\"][\"publishedAt\"]\n",
    "                    except KeyError:\n",
    "                        publish_date = float('nan')\n",
    "                    try:\n",
    "                        default_language = video[\"snippet\"][\"defaultLanguage\"]\n",
    "                    except KeyError:\n",
    "                        default_language = float('nan')\n",
    "                    try:\n",
    "                        duration = video[\"contentDetails\"][\"duration\"]\n",
    "                    except KeyError:\n",
    "                        duration = float('nan')\n",
    "                    try:\n",
    "                        has_paid_product_placement = video[\"contentDetails\"][\"hasPaidProductPlacement\"]\n",
    "                    except KeyError:\n",
    "                        has_paid_product_placement = float('nan')\n",
    "                    \n",
    "\n",
    "                    row = pd.DataFrame({\n",
    "                        \"video_id\": [video_id],\n",
    "                        \"channel_id\": [channel_id],\n",
    "                        \"video_title\": [video_title],\n",
    "                        \"view_count\": [view_count],\n",
    "                        \"like_count\": [like_count],\n",
    "                        \"dislike_count\": [dislike_count],\n",
    "                        \"comment_count\": [comment_count],\n",
    "                        \"publish_date\": [publish_date],\n",
    "                        \"default_language\": [default_language],\n",
    "                        \"duration\": [duration],\n",
    "                        \"has_paid_product_placement\": [has_paid_product_placement]\n",
    "                    })\n",
    "\n",
    "                    video_data = pd.concat([video_data, row], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error {e}\")\n",
    "            video_response = {\"items\": []}\n",
    "\n",
    "        if len(video_data) > 0:    \n",
    "            video_data.to_csv(video_data_path, index=False)\n",
    "    \n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data_path = f\"ChannelID_Data.csv\"\n",
    "video_data_path = f\"video_data.csv\"\n",
    "\n",
    "channel_data =  pd.read_csv(channel_data_path)\n",
    "video_data = pd.read_csv(video_data_path)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = channel_data.drop(columns=['Unnamed: 0'])\n",
    "video_data = video_data.drop(columns=['dislike_count'])\n",
    "\n",
    "# merge by channel_id\n",
    "merged_data = pd.merge(channel_data, video_data, on=\"channel_id\")\n",
    "display(merged_data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename Category to category\n",
    "merged_data.rename(columns = {'Category':'category'}, inplace = True)\n",
    "\n",
    "#rename view_x to channel_view_count\n",
    "merged_data.rename(columns = {'view_count_x':'channel_view_count'}, inplace = True)\n",
    "\n",
    "#rename view_y to video_view_count\n",
    "merged_data.rename(columns = {'view_count_y':'video_view_count'}, inplace = True)\n",
    "\n",
    "# duration in seconds\n",
    "merged_data[\"duration\"] = merged_data[\"duration\"].apply(lambda x: pd.to_timedelta(x).seconds)\n",
    "\n",
    "# convert publish_date to datetime\n",
    "merged_data[\"publish_date\"] = pd.to_datetime(merged_data[\"publish_date\"])\n",
    "\n",
    "# change default_language nan to \"none\"\n",
    "merged_data[\"default_language\"] = merged_data[\"default_language\"].fillna(\"none\")\n",
    "\n",
    "# drop has paid product placement\n",
    "merged_data = merged_data.drop(columns=[\"has_paid_product_placement\"])\n",
    "\n",
    "# drop nan values\n",
    "merged_data = merged_data.dropna()\n",
    "\n",
    "# convert number data to ints\n",
    "merged_data[\"video_view_count\"] = merged_data[\"video_view_count\"].astype(int)\n",
    "merged_data[\"channel_view_count\"] = merged_data[\"channel_view_count\"].astype(int)\n",
    "merged_data[\"like_count\"] = merged_data[\"like_count\"].astype(int)\n",
    "merged_data[\"comment_count\"] = merged_data[\"comment_count\"].astype(int)\n",
    "merged_data[\"subscriber_count\"] = merged_data[\"subscriber_count\"].astype(int)\n",
    "merged_data[\"video_count\"] = merged_data[\"video_count\"].astype(int)\n",
    "\n",
    "display(merged_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add is in covid column (2020-2021)\n",
    "merged_data[\"is_in_covid\"] = merged_data[\"publish_date\"].apply(lambda x: 1 if x.year >= 2020 and x.year <= 2021 else 0)\n",
    "\n",
    "# engagment_comments (comments/video_view)\n",
    "merged_data[\"engagement_comments\"] = merged_data[\"comment_count\"] / merged_data[\"video_view_count\"]\n",
    "\n",
    "# engagment_likes (likes/video_view)\n",
    "merged_data[\"engagement_likes\"] = merged_data[\"like_count\"] / merged_data[\"video_view_count\"]\n",
    "\n",
    "# engagment_subscribers (video_view/subscribers)\n",
    "merged_data[\"engagement_subscribers\"] = merged_data[\"video_view_count\"] / merged_data[\"subscriber_count\"]\n",
    "\n",
    "# view per subscriber (channel_view/subscribers)\n",
    "merged_data[\"view_per_subscriber\"] = merged_data[\"channel_view_count\"] / merged_data[\"subscriber_count\"]\n",
    "\n",
    "# video view per total channel view (video_view/channel_view)\n",
    "merged_data[\"video_view_per_total_channel_view\"] = merged_data[\"video_view_count\"] / merged_data[\"channel_view_count\"]\n",
    "\n",
    "# video views per video count (video_view/video_count)\n",
    "merged_data[\"video_views_per_video_count\"] = merged_data[\"channel_view_count\"] / merged_data[\"video_count\"]\n",
    "\n",
    "display(merged_data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def scatter_plot(x, x_title, y, y_title, in_data, out_data):\n",
    "    # Get unique categories\n",
    "    categories = in_data[\"category\"].unique()\n",
    "\n",
    "    # Set up figure size for each category\n",
    "    for i, category in enumerate(categories):\n",
    "        # Separate the data for the current category\n",
    "        category_data = in_data[in_data[\"category\"] == category]\n",
    "        category_filtered_out_data = out_data[out_data[\"category\"] == category]\n",
    "        \n",
    "        # Create a figure for scatter plot\n",
    "        fig = plt.figure(figsize=(7, 6))\n",
    "        \n",
    "        # Choose a color from Seaborn's color palette\n",
    "        color = sns.color_palette(\"husl\", len(categories))[i]\n",
    "        \n",
    "        # Scatter plot (highlighted data within duration < 2000)\n",
    "        ax = plt.subplot()\n",
    "        sns.regplot(x=x, y=y, data=category_data, ax=ax, color=color)\n",
    "\n",
    "        # Plot the filtered-out data (background points with different color and transparency)\n",
    "        sns.scatterplot(x=x, y=y, data=category_filtered_out_data, ax=ax, \n",
    "                        color='gray', alpha=0.4, label=\"Filtered Out\", s=50)\n",
    "        \n",
    "        # Calculate Pearson correlation\n",
    "        pear = pearsonr(category_data[x], category_data[y])\n",
    "        \n",
    "        # Set title and labels\n",
    "        ax.set_title(f\"Category: {category} | Pearson Correlation: {pear[0]:.3f} | P-Value: {pear[1]:.3f}\")\n",
    "        ax.set_xlabel(x_title)\n",
    "        ax.set_ylabel(y_title)\n",
    "        \n",
    "        # Show the scatter plot for the current category\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def distribution_plot(x, x_title, in_data):\n",
    "    # Get unique categories\n",
    "    categories = in_data[\"category\"].unique()\n",
    "\n",
    "    # Set up figure size and create a figure for the distribution plot\n",
    "    fig = plt.figure(figsize=(7, 6))\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    # Plot each category on the same axis\n",
    "    for i, category in enumerate(categories):\n",
    "        # Separate the data for the current category\n",
    "        category_data = in_data[in_data[\"category\"] == category]\n",
    "\n",
    "        # Choose a color from Seaborn's color palette\n",
    "        color = sns.color_palette(\"husl\", len(categories))[i]\n",
    "\n",
    "\n",
    "        # Distribution plot (KDE), normalized and without fill\n",
    "        sns.kdeplot(category_data[x], ax=ax, color=color, fill=True, common_norm=True, label=category, log_scale=True, alpha=0.05)\n",
    "\n",
    "    # Set plot title and labels\n",
    "    ax.set_title(f\"{x_title} Distribution by Category\")\n",
    "    ax.set_xlabel(f\" log scale {x_title}\")\n",
    "    \n",
    "    # Display the legend for categories\n",
    "    ax.legend(title=\"Category\")\n",
    "\n",
    "    # Show the distribution plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_shorts = merged_data[merged_data[\"duration\"] > 60]\n",
    "only_shorts = merged_data[merged_data[\"duration\"] <= 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_plot(\"duration\",\"Duration (seconds)\",merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_plot(\"duration\",\"Duration (seconds)\",\"video_view_count\",\"Video Views\",no_shorts,only_shorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution_plot(\"video_view_count\",\"Video Views\",no_shorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_plot(\"duration\",\"Duration (seconds)\",\"comment_count\",\"Comment Count\",no_shorts,only_shorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution_plot(\"comment_count\",\"Comment Count\",no_shorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot_compare_multiple_columns(cat_col, cols, col_titles, data):\n",
    "    # Get unique categories\n",
    "    categories = data[cat_col].unique()\n",
    "\n",
    "    # Prepare data for bar plot\n",
    "    bar_data = []\n",
    "    for category in categories:\n",
    "        category_data = data[data[cat_col] == category]\n",
    "        means = [category_data[col].mean() for col in cols]\n",
    "        bar_data.append([category] + means)\n",
    "    \n",
    "    # Convert to DataFrame for easier plotting\n",
    "    bar_df = pd.DataFrame(bar_data, columns=[cat_col] + col_titles)\n",
    "\n",
    "    # Melt the DataFrame to have it in long format suitable for Seaborn\n",
    "    bar_df_melted = pd.melt(bar_df, id_vars=[cat_col], value_vars=col_titles, \n",
    "                            var_name='Metric', value_name='Mean Value')\n",
    "\n",
    "    # Create bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=cat_col, y='Mean Value', hue='Metric', data=bar_df_melted)\n",
    "    \n",
    "    # Set plot labels and title\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.title(f'Comparison of Metrics by {cat_col}')\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar plots comparing engagment for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar_plot_compare_multiple_columns(\"category\",[\"video_view_count\",\"comment_count\"],[\"Video Views\",\"Comment Count\"],no_shorts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar_plot_compare_multiple_columns(\"category\",[\"video_view_count\",\"like_count\"],[\"Video Views\",\"Like Count\"],no_shorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot_compare_multiple_columns(\"category\",[\"engagement_likes\",\"engagement_comments\"],[\"engagement_likes\",\"engagement_comments\"],merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def compare_two_categories_distributions(category1, category2, x_title, metrics, data):\n",
    "    # Subset the data for the two categories\n",
    "    data_cat1 = data[data[\"category\"] == category1]\n",
    "    data_cat2 = data[data[\"category\"] == category2]\n",
    "\n",
    "    # Calculate the means of each metric for both categories\n",
    "    mean_likes_cat1 = data_cat1[metrics[0]].mean()\n",
    "    mean_likes_cat2 = data_cat2[metrics[0]].mean()\n",
    "    mean_comments_cat1 = data_cat1[metrics[1]].mean()\n",
    "    mean_comments_cat2 = data_cat2[metrics[1]].mean()\n",
    "\n",
    "    # Calculate effect sizes (mean differences)\n",
    "    effect_size_likes = mean_likes_cat1 - mean_likes_cat2\n",
    "    effect_size_comments = mean_comments_cat1 - mean_comments_cat2\n",
    "\n",
    "    # Perform t-tests for both metrics\n",
    "    ttest_likes = stats.ttest_ind(data_cat1[metrics[0]], data_cat2[metrics[0]], nan_policy='omit')\n",
    "    ttest_comments = stats.ttest_ind(data_cat1[metrics[1]], data_cat2[metrics[1]], nan_policy='omit')\n",
    "\n",
    "    # Set up a side-by-side plot (2 columns, 1 row)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Plot distributions for engagement_likes\n",
    "    sns.kdeplot(data_cat1[metrics[0]], ax=axes[0], label=category1, color='blue', fill=True)\n",
    "    sns.kdeplot(data_cat2[metrics[0]], ax=axes[0], label=category2, color='red', fill=True)\n",
    "    axes[0].set_title(f\"Likes Per View Distribution\\np-value: {ttest_likes.pvalue:.5f}, Mean diff: {effect_size_likes:.5f}\")\n",
    "    axes[0].set_xlabel(\"Likes Per View\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Plot distributions for engagement_comments\n",
    "    sns.kdeplot(data_cat1[metrics[1]], ax=axes[1], label=category1, color='blue', fill=True)\n",
    "    sns.kdeplot(data_cat2[metrics[1]], ax=axes[1], label=category2, color='red', fill=True)\n",
    "    axes[1].set_title(f\"Comment Per View Distribution\\np-value: {ttest_comments.pvalue:.5f}, Mean diff: {effect_size_comments:.5f}\")\n",
    "    axes[1].set_xlabel(\"Comment Per View\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# combine gaminga nd sports into one category and everythoiing else into other\n",
    "gaming_and_sports_data = merged_data.copy()\n",
    "gaming_and_sports_data[\"category\"] = gaming_and_sports_data[\"category\"].apply(lambda x: \"Gaming & Sports\" if x in [\"Gaming\", \"Sports\"] else \"Other\")\n",
    "\n",
    "# Example usage\n",
    "compare_two_categories_distributions(\"Gaming\", \"Sports\", \"Category Comparison\", \n",
    "                                     [\"engagement_likes\", \"engagement_comments\"], merged_data)\n",
    "\n",
    "compare_two_categories_distributions(\"Gaming & Sports\", \"Other\", \"Category Comparison\", \n",
    "                                     [\"engagement_likes\", \"engagement_comments\"], gaming_and_sports_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average views per category by year line plot\n",
    "\n",
    "def line_plot_average_views_per_category_by_year(data):\n",
    "    # Convert publish_date to datetime if not already\n",
    "    data[\"publish_date\"] = pd.to_datetime(data[\"publish_date\"])\n",
    "    data[\"year\"] = data[\"publish_date\"].dt.year\n",
    "\n",
    "    # Group the data by year and category, and calculate the mean of video_view_count\n",
    "    grouped_data = data.groupby([\"year\", \"category\"])[\"video_view_count\"].sum().reset_index()\n",
    "\n",
    "    # Create line plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.lineplot(x='year', y='video_view_count', hue='category', data=grouped_data)\n",
    "    \n",
    "    # Set plot labels and title\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Average Video Views')\n",
    "    plt.title('Average Video Views per Category by Year')\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line_plot_average_views_per_category_by_year(no_shorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_plot_covid(x, x_title, in_data):\n",
    "    # Get unique categories\n",
    "    categories = in_data[\"category\"].unique()\n",
    "\n",
    "    # Set up figure size for each category\n",
    "    for i, category in enumerate(categories):\n",
    "        # Separate the data for the current category\n",
    "        category_data = in_data[in_data[\"category\"] == category]\n",
    "        \n",
    "        # Create a figure for the distribution plot\n",
    "        fig = plt.figure(figsize=(7, 6))\n",
    "        \n",
    "        # Choose a color from Seaborn's color palette\n",
    "        color = sns.color_palette(\"husl\", len(categories))[i]\n",
    "        \n",
    "        # Distribution plot (KDE)\n",
    "        ax = plt.subplot()\n",
    "\n",
    "        sns.kdeplot(category_data[x], ax=ax, color=color, fill=True)\n",
    "        ax.set_title(f\"{x_title} Distribution for {category}\")\n",
    "        ax.set_xlabel(x_title)\n",
    "\n",
    "\n",
    "        # Calculate the mean of x and add a vertical line\n",
    "        mean_x = category_data[x].mean()\n",
    "        ax.axvline(mean_x, color=color, linestyle='--', linewidth=2)\n",
    "        \n",
    "        # Add a label at the mean line\n",
    "        #check for date time\n",
    "        if x == \"publish_date\":\n",
    "            ax.text(mean_x, ax.get_ylim()[1] * 0.9, f'Mean: {mean_x.strftime(\"%Y-%m-%d\")}', color=color, \n",
    "                ha='center', va='top', fontsize=10, backgroundcolor='white', rotation=90)\n",
    "        else:\n",
    "            ax.text(mean_x, ax.get_ylim()[1] * 0.9, f'Mean: {mean_x:.2f}', color=color, \n",
    "                ha='center', va='top', fontsize=10, backgroundcolor='white', rotation=90)\n",
    "            \n",
    "        # add in covid range\n",
    "        _2020_date = pd.to_datetime(\"2020-01-01\")\n",
    "        _2021_date = pd.to_datetime(\"2021-12-31\")\n",
    "        _2020_half_date = pd.to_datetime(\"2020-12-31\")\n",
    "        ax.axvline(_2020_date, color='red', linestyle='--', linewidth=2)\n",
    "        ax.axvline(_2021_date, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "        #shade the covid range\n",
    "        ax.axvspan(_2020_date, _2021_date, color='red', alpha=0.1)\n",
    "\n",
    "\n",
    "        ax.text(_2020_half_date, ax.get_ylim()[1]*.1, f'COVID-19', color='red', \n",
    "                 ha='center', va='top', fontsize=10, backgroundcolor='white')\n",
    "        \n",
    "        # Show the distribution plot for the current category\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show distribution of videos by publish date\n",
    "# distribution_plot_covid(\"publish_date\",\"Video Publish Date\",no_shorts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtubeapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
