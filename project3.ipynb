{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_by_category = {\n",
    "    'Auto & Vehicles': [\n",
    "                'Stokes twins squad', \n",
    "                'DASH CAM CN', \n",
    "                'Supercar Blondie',\n",
    "                'The Classic Motorcycle Channel',\n",
    "                'Salai Sathish777',\n",
    "                'Exotic Rubber',\n",
    "                'Sarah Lezito',\n",
    "                'San Razka',\n",
    "                'Suvo Stunts',\n",
    "                'Nikolai Savic'\n",
    "                ],\n",
    "    'Entertainment': [\n",
    "                'Anaya Kandhal',\n",
    "                'Toys and Colors',\n",
    "                'J House jr.',\n",
    "                'Sierra & Rhia FAM',\n",
    "                'KL BRO Biju Rithvik',\n",
    "                'StarPlus',\n",
    "                'MrBeast',\n",
    "                'HAR PAL GEO',\n",
    "                'Upin & Ipin',\n",
    "                'Dylan Anderson'\n",
    "                ],\n",
    "    'Gaming': [\n",
    "                'Linh Nhi Shorts',\n",
    "                'Animal World',\n",
    "                'LankyBox',\n",
    "                'Kissy Show',\n",
    "                'FACT FIRE KING',\n",
    "                'Daquavis',\n",
    "                'Sinotal Gaming',\n",
    "                ' LetsPlay',\n",
    "                'Nahz',\n",
    "                'Canva India'\n",
    "                ],\n",
    "    'Sports': [\n",
    "                'Celine Dept',\n",
    "                'WWE',\n",
    "                'Red Bull',\n",
    "                'House of Highlights',\n",
    "                'YOLO AVENTURAS',\n",
    "                'SportsNation',\n",
    "                'UR · Cristiano',\n",
    "                'Omar Raja - ESPN',\n",
    "                'ESPN',\n",
    "                'Score 90 Shorts'\n",
    "                ],\n",
    "    'Music': [ \n",
    "                'Seyhan Müzik',\n",
    "                'T-Series',\n",
    "                'SHADE Of Love',\n",
    "                'Sony Music South',\n",
    "                'El Payaso Plim Plim',\n",
    "                'Saregama Music',\n",
    "                'Zee Music Company',\n",
    "                'Prvnci',\n",
    "                'Tips Official',\n",
    "                'The Weeknd'\n",
    "                ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "with open('secret/secret.txt') as f:\n",
    "    api_key = f.readline().strip()\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Cache\n",
    "\n",
    "Will use 8900 tokens so you can only run it once a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = \".cache\"\n",
    "channel_data_path = f\"{cache_path}/channel_data.csv\"\n",
    "video_data_path = f\"{cache_path}/video_data.csv\"\n",
    "comment_data_path = f\"{cache_path}/comment_data.csv\"\n",
    "\n",
    "cache_exists = os.path.exists(cache_path)\n",
    "\n",
    "if not cache_exists:\n",
    "    os.makedirs(cache_path)\n",
    "\n",
    "channel_data_exist = os.path.exists(channel_data_path)\n",
    "\n",
    "video_data_exist = os.path.exists(video_data_path)\n",
    "\n",
    "comment_data_exist = os.path.exists(comment_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads channel data\n",
    "uses 100 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if channel_data_exist:\n",
    "    channel_data = pd.read_csv(channel_data_path)\n",
    "else:\n",
    "    channel_data = pd.DataFrame(columns=[\"channel_id\", \"category\", \"channel_name\", \"subscriber_count\", \"video_count\", \"view_count\"])\n",
    "    for category in channels_by_category:\n",
    "        for channel in channels_by_category[category]:\n",
    "            try:\n",
    "                id_request = youtube.search().list(\n",
    "                    part=\"id\",\n",
    "                    maxResults=1,\n",
    "                    type=\"channel\",\n",
    "                    q=channel,\n",
    "                    order=\"viewCount\"\n",
    "                )\n",
    "                id_response = id_request.execute()\n",
    "                \n",
    "                channel_id = id_response[\"items\"][0][\"id\"][\"channelId\"]\n",
    "\n",
    "                request = youtube.channels().list(\n",
    "                    part=\"statistics\",\n",
    "                    id=channel_id\n",
    "                )\n",
    "                response = request.execute()\n",
    "\n",
    "                subscriber_count = response[\"items\"][0][\"statistics\"][\"subscriberCount\"]\n",
    "                video_count = response[\"items\"][0][\"statistics\"][\"videoCount\"]\n",
    "                view_count = response[\"items\"][0][\"statistics\"][\"viewCount\"]\n",
    "\n",
    "                row = {\n",
    "                    \"channel_id\": channel_id,\n",
    "                    \"category\": category,\n",
    "                    \"channel_name\": channel,\n",
    "                    \"subscriber_count\": subscriber_count,\n",
    "                    \"video_count\": video_count,\n",
    "                    \"view_count\": view_count\n",
    "                }\n",
    "\n",
    "                channel_data = pd.concat([channel_data, row], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error on channel: {channel}: {e}\")\n",
    "                if e.status_code == 403:\n",
    "                    break\n",
    "                continue\n",
    "    \n",
    "    channel_data.to_csv(channel_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads video data\n",
    "uses 550 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if video_data_exist:\n",
    "    video_data = pd.read_csv(video_data_path)\n",
    "else:\n",
    "    video_data = pd.DataFrame(columns=[\"video_id\", \"channel_id\", \"video_title\", \"view_count\", \"like_count\", \"dislike_count\", \"comment_count\"])\n",
    "    for channel_id in channel_data[\"channel_id\"]:\n",
    "        try:\n",
    "            request = youtube.search().list(\n",
    "                part=\"id\",\n",
    "                maxResults=10,\n",
    "                type=\"video\",\n",
    "                channelId=channel_id,\n",
    "                order=\"viewCount\"\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            for item in response[\"items\"]:\n",
    "                video_id = item[\"id\"][\"videoId\"]\n",
    "\n",
    "                video_request = youtube.videos().list(\n",
    "                    part=\"statistics\",\n",
    "                    id=video_id\n",
    "                )\n",
    "                video_response = video_request.execute()\n",
    "\n",
    "                view_count = video_response[\"items\"][0][\"statistics\"][\"viewCount\"]\n",
    "                like_count = video_response[\"items\"][0][\"statistics\"][\"likeCount\"]\n",
    "                dislike_count = video_response[\"items\"][0][\"statistics\"][\"dislikeCount\"]\n",
    "                comment_count = video_response[\"items\"][0][\"statistics\"][\"commentCount\"]\n",
    "\n",
    "                row = {\n",
    "                    \"video_id\": video_id,\n",
    "                    \"channel_id\": channel_id,\n",
    "                    \"video_title\": item[\"snippet\"][\"title\"],\n",
    "                    \"view_count\": view_count,\n",
    "                    \"like_count\": like_count,\n",
    "                    \"dislike_count\": dislike_count,\n",
    "                    \"comment_count\": comment_count\n",
    "                }\n",
    "\n",
    "                video_data = pd.concat([video_data, row], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error on channel: {channel_id}: {e}\")\n",
    "            if e.status_code == 403:\n",
    "                break\n",
    "            continue\n",
    "    \n",
    "    video_data.to_csv(video_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads comment data\n",
    "uses 8250 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if comment_data_exist:\n",
    "    comment_data = pd.read_csv(comment_data_path)\n",
    "else:\n",
    "    comment_data = pd.DataFrame(columns=[\"video_id\", \"comment\", \"like_count\", \"reply_count\"])\n",
    "    for video_id in video_data[\"video_id\"]:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=15\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            for item in response[\"items\"]:\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"]\n",
    "                like_count = item[\"snippet\"][\"topLevelComment\"][\"likeCount\"]\n",
    "                reply_count = item[\"snippet\"][\"totalReplyCount\"]\n",
    "\n",
    "                row = {\n",
    "                    \"video_id\": video_id,\n",
    "                    \"comment\": comment,\n",
    "                    \"like_count\": like_count,\n",
    "                    \"reply_count\": reply_count\n",
    "                }\n",
    "\n",
    "                comment_data = pd.concat([comment_data, row], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error on video: {video_id}: {e}\")\n",
    "            if e.status_code == 403:\n",
    "                    break\n",
    "            continue\n",
    "    \n",
    "    comment_data.to_csv(comment_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(channel_data.head())\n",
    "display(video_data.head())\n",
    "display(comment_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtubeapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
