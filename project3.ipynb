{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS_BY_CATEGORY = {\n",
    "    'Auto & Vehicles': {\n",
    "                'Stokes twins squad':'UCbp9MyKCTEww4CxEzc_Tp0Q', \n",
    "                'DASH CAM CN':'UCJZpPG8wegZJ3rsnc6-Bpnw', \n",
    "                'Supercar Blondie':'UC0_7evGVYla1lREeXjN_JLg',\n",
    "                'The Classic Motorcycle Channel':'UCtjWY31B54jqxRFQM9xyhDw',\n",
    "                'Salai Sathish777':'UCaEUPNkdnbQROROKm09SGoQ',\n",
    "                'Exotic Rubber':'UCF2eaKLl9I8yXg31FW3GH2g',\n",
    "                'Sarah Lezito':'UCT7dKiVfnUSRk7ckOfIwWvw',\n",
    "                'San Razka':'UCcDiv0JjkAnirZvcwcZYXTw',\n",
    "                'Suvo Stunts':'UCzRnN9ntMZf83mquKpT6a0w',\n",
    "                'Nikolai Savic':'UCqcRe8F3rETPbzOFJHzk'\n",
    "    },\n",
    "    'Entertainment': {\n",
    "                'Anaya Kandhal':'UCJTqi2KOenudYnEOUSAj5Hg',\n",
    "                'Toys and Colors':'UCIte5_YtyuMKsSytQDgWdMA',\n",
    "                'J House jr.':'UCGHGx_VOEWUE_WINENxxKbA',\n",
    "                'Sierra & Rhia FAM':'UCe6n0z9UbsxYCS8P83f84tw',\n",
    "                'KL BRO Biju Rithvik':'UCABNiUtltfp4piL69GD2BmA',\n",
    "                'StarPlus':'UCAGZZ-Ua-yB-fqObs1GKzag',\n",
    "                'MrBeast':'UClD832S2f_F_W4epwAd5sOw',\n",
    "                'HAR PAL GEO':'UCNoMrALPTsDJaNiIdMk_kCw',\n",
    "                'Upin & Ipin':'UCB8VtllrypUr7YP9WiYuXCA',\n",
    "                'Dylan Anderson':'UCRY8HfhFV5w9toYlR8bfupQ'\n",
    "    },\n",
    "    'Gaming': {\n",
    "                'Linh Nhi Shorts':'UCOGJ0sPUo9_39Qiru4Lx51w',\n",
    "                'Animal World':'UCEexsbjV02l4bPWfyNlMJ3A',\n",
    "                'LankyBox':'UCU7d91rxwcqHh-fSgCNU73Q',\n",
    "                'Kissy Show':'UCRA3T1IofrU3HSys0FJGbZQ',\n",
    "                'FACT FIRE KING':'UCDjrDvzuRUmwIBmY8GBOPVw',\n",
    "                'Daquavis':'UCvwYaSSj-ceh5-nfSv71WKw',\n",
    "                'Sinotal Gaming':'UCe6qB7dYiurwyKSxrgCdmLA',\n",
    "                'LetsPlay':'UCia7dsxxnoUsJMicn-0gbTw',\n",
    "                'Nahz':'UCq-BiqUyulZMOZEr0xtGOjg',\n",
    "                'Canva India':'UC2V8gNWRrOrBFOm08tNSugQ'\n",
    "    },\n",
    "    'Sports': {\n",
    "                'Celine Dept':'UCTq7Bs_Whk-WYwhU9CoezCQ',\n",
    "                'WWE':'UC2NNoTGy7-nNSA1DOefkCpA',\n",
    "                'Red Bull':'UCuLq0ME8tqK6pzCm9rpkwjQ',\n",
    "                'House of Highlights':'UCYXbyePIPf6lJkOuVvdugQw',\n",
    "                'YOLO AVENTURAS':'UCqTxve5-0sVxxBB8dX3DkFA',\n",
    "                'SportsNation':'UC7dzGIZnOoGVjODipT1183Q',\n",
    "                'UR · Cristiano':'UCHzgN0TNou2bCHkLsCV-tLw',\n",
    "                'Omar Raja - ESPN':'UCLFhLRABMCFl5H6hS-NgrPg',\n",
    "                'ESPN':'UCGVx9_dtZD0MuFdNxmNL1eg',\n",
    "                'Score 90 Shorts':'UCbVtlOOHT_3VMKhuM1d9ziA'\n",
    "    },\n",
    "    'Music': { \n",
    "                'Seyhan Müzik':'UCNqr9QkPw2ThS6reZ_VglVA',\n",
    "                'T-Series':'UCpN-WGQgGsOrXm7nHXDdTDA',\n",
    "                'SHADE Of Love':'UCR5hcvWZc9XlSEK7sPlMpTw',\n",
    "                'Sony Music South':'UCXNslTpQcYUNS1g6TEwQ_bQ',\n",
    "                'El Payaso Plim Plim':'UCHU3DmaXhrrZ9oBQF7TnpIQ',\n",
    "                'Saregama Music':'UCerohJ7AcKkilNALvAx6-_w',\n",
    "                'Zee Music Company':'UCE-C1Zk9eL5K-aGJcLGurrw',\n",
    "                # 'Prvnci':'',\n",
    "                'Tips Official':'UCohjG0ZUU_VTvgZ_EpM0OrA',\n",
    "                'The Weeknd':'UCPY2tjsvvV_Y1l_n9LxaLnQ'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secret/secret.txt') as f:\n",
    "    api_key = f.readline().strip()\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_data(channel_data_path, channels_by_category):    \n",
    "    if os.path.exists(channel_data_path):\n",
    "        channel_data = pd.read_csv(channel_data_path)\n",
    "    else:\n",
    "        channel_data = pd.DataFrame(columns=[\"channel_id\", \"category\", \"channel_name\", \"subscriber_count\", \"video_count\", \"view_count\", \"playlist_id\"])\n",
    "        for category in channels_by_category:\n",
    "            for channel in channels_by_category[category]:\n",
    "                channel_id = channels_by_category[category][channel]\n",
    "                try:\n",
    "\n",
    "                    request = youtube.channels().list(\n",
    "                        part=\"statistics,contentDetail\",\n",
    "                        id=channel_id\n",
    "                    )\n",
    "                    response = request.execute()\n",
    "                    try:\n",
    "                        subscriber_count = response[\"items\"][0][\"statistics\"][\"subscriberCount\"]\n",
    "                    except KeyError:\n",
    "                        subscriber_count = float('nan')\n",
    "                    try:\n",
    "                        video_count = response[\"items\"][0][\"statistics\"][\"videoCount\"]\n",
    "                    except KeyError:\n",
    "                        video_count = float('nan')\n",
    "                    try:\n",
    "                        view_count = response[\"items\"][0][\"statistics\"][\"viewCount\"]\n",
    "                    except KeyError:\n",
    "                        view_count = float('nan')\n",
    "\n",
    "                    try:\n",
    "                        playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "                    except KeyError:\n",
    "                        playlist_id = float('nan')\n",
    "                        \n",
    "                    row = pd.DataFrame({\n",
    "                        \"channel_id\": [channel_id],\n",
    "                        \"category\": [category],\n",
    "                        \"channel_name\": [channel],\n",
    "                        \"subscriber_count\": [subscriber_count],\n",
    "                        \"video_count\": [video_count],\n",
    "                        \"view_count\": [view_count],\n",
    "                        \"playlist_id\": [playlist_id]\n",
    "                    })\n",
    "\n",
    "                    channel_data = pd.concat([channel_data, row], ignore_index=True)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error on channel: {channel}: {e}\")\n",
    "                    if hasattr(e, 'status_code') and e.status_code == 403:\n",
    "                        break\n",
    "                    continue\n",
    "        \n",
    "        if len(channel_data) > 0:\n",
    "            channel_data.to_csv(channel_data_path, index=False)\n",
    "    \n",
    "    return channel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_data(video_data_path, channel_data):\n",
    "    if os.path.exists(video_data_path):\n",
    "        video_data = pd.read_csv(video_data_path)\n",
    "    else:\n",
    "        video_data = pd.DataFrame(columns=[\"video_id\", \"channel_id\", \"video_title\", \"view_count\", \"like_count\", \"dislike_count\", \"comment_count\"])\n",
    "        video_ids = {}\n",
    "        all_video_ids = \"\"\n",
    "        try:\n",
    "            for playlist_id in channel_data[\"playlist_id\"]:\n",
    "                \n",
    "                    request = youtube.playlistItems.list(\n",
    "                        part=\"id\",\n",
    "                        playlist_id=playlist_id\n",
    "                    )\n",
    "\n",
    "                    response = request.execute()\n",
    "\n",
    "                    for item in response[\"items\"][:10]:\n",
    "                        try:\n",
    "                            video_ids[item[\"id\"][\"videoId\"]] = playlist_id\n",
    "                            if all_video_ids == \"\":\n",
    "                                all_video_ids += item[\"id\"][\"videoId\"]\n",
    "                            else:\n",
    "                                all_video_ids += ',' + item[\"id\"][\"videoId\"]\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "\n",
    "            video_request = youtube.videos().list(\n",
    "                part=\"statistics\",\n",
    "                id=all_video_ids\n",
    "            )\n",
    "            video_response = video_request.execute()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error {e}\")\n",
    "            video_response = {\"items\": []}\n",
    "\n",
    "        for video in video_response[\"items\"]:\n",
    "\n",
    "            try:\n",
    "                video_id = video[\"id\"]\n",
    "            except KeyError:\n",
    "                video_id = float('nan')\n",
    "            try:\n",
    "                view_count = video[\"statistics\"][\"viewCount\"]\n",
    "            except KeyError:\n",
    "                view_count = float('nan')\n",
    "            try:\n",
    "                like_count = video[\"statistics\"][\"likeCount\"]\n",
    "            except KeyError:\n",
    "                like_count = float('nan')\n",
    "            try:\n",
    "                dislike_count = video[\"statistics\"][\"dislikeCount\"]\n",
    "            except KeyError:\n",
    "                dislike_count = float('nan')\n",
    "            try:\n",
    "                comment_count = video[\"statistics\"][\"commentCount\"]\n",
    "            except KeyError:\n",
    "                comment_count = float('nan')\n",
    "\n",
    "            row = pd.DataFrame({\n",
    "                \"video_id\": [video_id],\n",
    "                \"playlist_id\": [video_ids[video_id]],\n",
    "                \"video_title\": [item[\"snippet\"][\"title\"]],\n",
    "                \"view_count\": [view_count],\n",
    "                \"like_count\": [like_count],\n",
    "                \"dislike_count\": [dislike_count],\n",
    "                \"comment_count\": [comment_count]\n",
    "            })\n",
    "\n",
    "            video_data = pd.concat([video_data, row], ignore_index=True)\n",
    "\n",
    "        if len(video_data) > 0:    \n",
    "            video_data.to_csv(video_data_path, index=False)\n",
    "    \n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_data(comment_data_path, video_data):\n",
    "    if os.path.exists(comment_data_path):\n",
    "        comment_data = pd.read_csv(comment_data_path)\n",
    "    else:\n",
    "        comment_data = pd.DataFrame(columns=[\"video_id\", \"comment\", \"like_count\", \"reply_count\"])\n",
    "        for video_id in video_data[\"video_id\"]:\n",
    "            try:\n",
    "                request = youtube.commentThreads().list(\n",
    "                    part=\"snippet\",\n",
    "                    videoId=video_id,\n",
    "                    maxResults=15\n",
    "                )\n",
    "                response = request.execute()\n",
    "\n",
    "                for item in response[\"items\"]:\n",
    "                    try:\n",
    "                        comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"]\n",
    "                    except KeyError:\n",
    "                        comment = float('nan')\n",
    "                    try:\n",
    "                        like_count = item[\"snippet\"][\"topLevelComment\"][\"likeCount\"]\n",
    "                    except KeyError:\n",
    "                        like_count = float('nan')\n",
    "                    try:\n",
    "                        reply_count = item[\"snippet\"][\"totalReplyCount\"]\n",
    "                    except KeyError:\n",
    "                        reply_count = float('nan')\n",
    "\n",
    "                    row = pd.DataFrame({\n",
    "                        \"video_id\": [video_id],\n",
    "                        \"comment\": [comment],\n",
    "                        \"like_count\": [like_count],\n",
    "                        \"reply_count\": [reply_count]\n",
    "                    })\n",
    "\n",
    "                    comment_data = pd.concat([comment_data, row], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error on video: {video_id}: {e}\")\n",
    "                if hasattr(e, 'status_code') and e.status_code == 403:\n",
    "                        break\n",
    "                continue\n",
    "        \n",
    "        if len(comment_data) > 0:\n",
    "            comment_data.to_csv(comment_data_path, index=False)\n",
    "    \n",
    "    return comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_PATH = \".cache\"\n",
    "\n",
    "if not os.path.exists(CACHE_PATH):\n",
    "    os.makedirs(CACHE_PATH)\n",
    "\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on channel: Stokes twins squad: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/channels?part=statistics%2CcontentDetail&id=UCbp9MyKCTEww4CxEzc_Tp0Q&key=AIzaSyDqo7U_-fTqzXUq4jCmSqdiYCyVI5qoD7U&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">\n",
      "Error on channel: Anaya Kandhal: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/channels?part=statistics%2CcontentDetail&id=UCJTqi2KOenudYnEOUSAj5Hg&key=AIzaSyDqo7U_-fTqzXUq4jCmSqdiYCyVI5qoD7U&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">\n",
      "Error on channel: Linh Nhi Shorts: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/channels?part=statistics%2CcontentDetail&id=UCOGJ0sPUo9_39Qiru4Lx51w&key=AIzaSyDqo7U_-fTqzXUq4jCmSqdiYCyVI5qoD7U&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">\n",
      "Error on channel: Celine Dept: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/channels?part=statistics%2CcontentDetail&id=UCTq7Bs_Whk-WYwhU9CoezCQ&key=AIzaSyDqo7U_-fTqzXUq4jCmSqdiYCyVI5qoD7U&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">\n",
      "Error on channel: Seyhan Müzik: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/channels?part=statistics%2CcontentDetail&id=UCNqr9QkPw2ThS6reZ_VglVA&key=AIzaSyDqo7U_-fTqzXUq4jCmSqdiYCyVI5qoD7U&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">\n",
      "Error <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/videos?part=statistics&id=&key=AIzaSyDqo7U_-fTqzXUq4jCmSqdiYCyVI5qoD7U&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">\n"
     ]
    }
   ],
   "source": [
    "SEARCH = []\n",
    "\n",
    "if len(SEARCH) > 0: \n",
    "\n",
    "    for search in SEARCH:\n",
    "        \n",
    "        search_cache_path = f\"{CACHE_PATH}/{search}\"\n",
    "\n",
    "        if not os.path.exists(search_cache_path):\n",
    "            os.makedirs(search_cache_path)\n",
    "\n",
    "        channel_data_path = f\"{search_cache_path}/channel_data.csv\"\n",
    "        video_data_path = f\"{search_cache_path}/video_data.csv\"\n",
    "        comment_data_path = f\"{search_cache_path}/comment_data.csv\"\n",
    "        \n",
    "\n",
    "        channels_by_category = {}\n",
    "\n",
    "        request = youtube.search().list(\n",
    "            part=\"ids,snippet\",\n",
    "            maxResults=10,\n",
    "            type=\"channel\",\n",
    "            q=search,\n",
    "            order=\"viewCount\"\n",
    "        )\n",
    "\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response[\"items\"]:\n",
    "            channels_by_category[item[\"snippet\"][\"title\"]] = item[\"id\"][\"channelId\"]\n",
    "\n",
    "        channel_data = get_channel_data(channel_data_path, channels_by_category)\n",
    "        video_data = get_video_data(video_data_path, channel_data)\n",
    "        comment_data = get_comment_data(comment_data_path, video_data)\n",
    "\n",
    "        data[search] = {\n",
    "            \"channel_data\": channel_data,\n",
    "            \"video_data\": video_data,\n",
    "            \"comment_data\": comment_data\n",
    "        }\n",
    "\n",
    "\n",
    "channel_data_path = f\"{CACHE_PATH}/channel_data.csv\"\n",
    "video_data_path = f\"{CACHE_PATH}/video_data.csv\"\n",
    "comment_data_path = f\"{CACHE_PATH}/comment_data.csv\"\n",
    "\n",
    "channel_data = get_channel_data(channel_data_path, CHANNELS_BY_CATEGORY)\n",
    "video_data = get_video_data(video_data_path, channel_data)\n",
    "comment_data = get_comment_data(comment_data_path, video_data)\n",
    "\n",
    "data[\"default\"] = {\n",
    "    \"channel_data\": channel_data,\n",
    "    \"video_data\": video_data,\n",
    "    \"comment_data\": comment_data\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_IN_EXISTING = []\n",
    "\n",
    "for csv in LOAD_IN_EXISTING:\n",
    "    if os.path.exists(csv):\n",
    "        search = csv.split(\"/\")[-1]\n",
    "        type = csv.split(\"/\")[-2]\n",
    "\n",
    "        if data.get(search) is None:\n",
    "            data[search] = {}\n",
    "            data[search][type] = pd.read_csv(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>category</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>subscriber_count</th>\n",
       "      <th>video_count</th>\n",
       "      <th>view_count</th>\n",
       "      <th>playlist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [channel_id, category, channel_name, subscriber_count, video_count, view_count, playlist_id]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [video_id, channel_id, video_title, view_count, like_count, dislike_count, comment_count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [video_id, comment, like_count, reply_count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in data:\n",
    "    print(key)\n",
    "    for type in data[key]:\n",
    "        display(data[key][type].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtubeapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
